{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Regressão Múltipla\n",
    "\n",
    "* Com o sucesso do projeto do capítulo 14, a vice-presidente da empresa acredita que você pode fazer melhor. Para isso, você colheu dados adicionais: para cada usuário, além da quantidade de amigos, você sabe quantas horas ele trabalha por dia e se ele tem um PhD. \n",
    "\n",
    "* Você deseja utilizar esses dados adicionais no seu modelo e cria a seguinte hipótese:\n",
    "\n",
    " minutes = $\\alpha + \\beta_{1}$friends + $\\beta_{2}$work hours + $\\beta_{3}$phd + $\\varepsilon$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1,49,4,0],[1,41,9,0],[1,40,8,0],[1,25,6,0],[1,21,1,0],[1,21,0,0],[1,19,3,0],[1,19,0,0],[1,18,9,0],[1,18,8,0],[1,16,4,0],[1,15,3,0],[1,15,0,0],[1,15,2,0],[1,15,7,0],[1,14,0,0],[1,14,1,0],[1,13,1,0],[1,13,7,0],[1,13,4,0],[1,13,2,0],[1,12,5,0],[1,12,0,0],[1,11,9,0],[1,10,9,0],[1,10,1,0],[1,10,1,0],[1,10,7,0],[1,10,9,0],[1,10,1,0],[1,10,6,0],[1,10,6,0],[1,10,8,0],[1,10,10,0],[1,10,6,0],[1,10,0,0],[1,10,5,0],[1,10,3,0],[1,10,4,0],[1,9,9,0],[1,9,9,0],[1,9,0,0],[1,9,0,0],[1,9,6,0],[1,9,10,0],[1,9,8,0],[1,9,5,0],[1,9,2,0],[1,9,9,0],[1,9,10,0],[1,9,7,0],[1,9,2,0],[1,9,0,0],[1,9,4,0],[1,9,6,0],[1,9,4,0],[1,9,7,0],[1,8,3,0],[1,8,2,0],[1,8,4,0],[1,8,9,0],[1,8,2,0],[1,8,3,0],[1,8,5,0],[1,8,8,0],[1,8,0,0],[1,8,9,0],[1,8,10,0],[1,8,5,0],[1,8,5,0],[1,7,5,0],[1,7,5,0],[1,7,0,0],[1,7,2,0],[1,7,8,0],[1,7,10,0],[1,7,5,0],[1,7,3,0],[1,7,3,0],[1,7,6,0],[1,7,7,0],[1,7,7,0],[1,7,9,0],[1,7,3,0],[1,7,8,0],[1,6,4,0],[1,6,6,0],[1,6,4,0],[1,6,9,0],[1,6,0,0],[1,6,1,0],[1,6,4,0],[1,6,1,0],[1,6,0,0],[1,6,7,0],[1,6,0,0],[1,6,8,0],[1,6,4,0],[1,6,2,1],[1,6,1,1],[1,6,3,1],[1,6,6,1],[1,6,4,1],[1,6,4,1],[1,6,1,1],[1,6,3,1],[1,6,4,1],[1,5,1,1],[1,5,9,1],[1,5,4,1],[1,5,6,1],[1,5,4,1],[1,5,4,1],[1,5,10,1],[1,5,5,1],[1,5,2,1],[1,5,4,1],[1,5,4,1],[1,5,9,1],[1,5,3,1],[1,5,10,1],[1,5,2,1],[1,5,2,1],[1,5,9,1],[1,4,8,1],[1,4,6,1],[1,4,0,1],[1,4,10,1],[1,4,5,1],[1,4,10,1],[1,4,9,1],[1,4,1,1],[1,4,4,1],[1,4,4,1],[1,4,0,1],[1,4,3,1],[1,4,1,1],[1,4,3,1],[1,4,2,1],[1,4,4,1],[1,4,4,1],[1,4,8,1],[1,4,2,1],[1,4,4,1],[1,3,2,1],[1,3,6,1],[1,3,4,1],[1,3,7,1],[1,3,4,1],[1,3,1,1],[1,3,10,1],[1,3,3,1],[1,3,4,1],[1,3,7,1],[1,3,5,1],[1,3,6,1],[1,3,1,1],[1,3,6,1],[1,3,10,1],[1,3,2,1],[1,3,4,1],[1,3,2,1],[1,3,1,1],[1,3,5,1],[1,2,4,1],[1,2,2,1],[1,2,8,1],[1,2,3,1],[1,2,1,1],[1,2,9,1],[1,2,10,1],[1,2,9,1],[1,2,4,1],[1,2,5,1],[1,2,0,1],[1,2,9,1],[1,2,9,1],[1,2,0,1],[1,2,1,1],[1,2,1,1],[1,2,4,1],[1,1,0,1],[1,1,2,1],[1,1,2,1],[1,1,5,1],[1,1,3,1],[1,1,10,1],[1,1,6,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,4,1],[1,1,9,1],[1,1,9,1],[1,1,4,1],[1,1,2,1],[1,1,9,1],[1,1,0,1],[1,1,8,1],[1,1,6,1],[1,1,1,1],[1,1,1,1],[1,1,5,1]]\n",
    "daily_minutes_good = [68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções Auxiliares\n",
    "from Codigos.linear_algebra import dot\n",
    "from Codigos.gradient_descent import minimize_stochastic\n",
    "from Codigos.simple_linear_regression import total_sum_of_squares\n",
    "from Codigos.stats import median, standard_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O Modelo\n",
    "\n",
    "* No capítulo 14 tinhamos um modelo na forma:\n",
    "\n",
    " $y_{i} = \\alpha + \\beta x_{i} + \\varepsilon_{i}$\n",
    " \n",
    "* Agora, cada entrada $x_{i}$ não é um único número mas um vetor de k números xi1,..., xik.\n",
    "\n",
    "* O modelo de regressão múltipla presume:\n",
    "\n",
    " $y_{i} = \\alpha + \\beta_{1}x_{i1} +$ ... $+ \\beta_{k}x_{ik} + \\varepsilon$\n",
    " \n",
    "* Para a regressão múltipla, o vetor de parâmetros é chamado de beta e são organizados assim:\n",
    " \n",
    " beta = [alpha, beta_i1, ..., beta_k]\n",
    " \n",
    "* e o vetor de entradas:\n",
    "\n",
    " x_i = [1, x_i1, ..., x_ik]\n",
    " \n",
    "* O nosso modelo é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_i, beta):\n",
    "    return dot(x_i, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustando o modelo\n",
    "\n",
    "* Escolheremos beta para minimizar a soma dos erros quadrados. \n",
    "* Para isso, utilizaremos o gradiente descendente.\n",
    "* Começaremos criando uma função de erro a minimizar. \n",
    "* Necessitamos do erro quadrado para uma simples previsão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(x_i, y_i, beta):\n",
    "    return y_i - predict(x_i, beta)\n",
    "\n",
    "def squared_error(x_i, y_i, beta):\n",
    "    return error(x_i, y_i, beta)**2\n",
    "\n",
    "def squared_error_gradient(x_i, y_i, beta):\n",
    "    # O gradiente (com respeito a beta) correspondente \n",
    "    # ao i-ésimo termo do erro quadrado\n",
    "    return [-2 * x_ij * error(x_i, y_i, beta)\n",
    "           for x_ij in x_i]\n",
    "\n",
    "# Agora é possível encontrar o beta ótimo usando o gradiente descendente aleatório\n",
    "import random\n",
    "def estimate_beta(x, y):\n",
    "    beta_initial = [random.random() for x_i in x[0]]\n",
    "    return minimize_stochastic(squared_error,\n",
    "                              squared_error_gradient,\n",
    "                              x, y,\n",
    "                              beta_initial,\n",
    "                              0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.619881701311712, 0.9702056472470465, -1.8671913880379478, 0.9163711597955347]\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "beta = estimate_beta(x, daily_minutes_good)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Com esses valores de beta, o modelo ficaria:\n",
    "\n",
    " minutos = 30,62 + 0,970 amigos - 1,867 horas de trabalho + 0,911 PhD\n",
    " \n",
    "### Interpretando o Modelo\n",
    "\n",
    "* Devemos pensar nos coeficientes dos modelos como representantes de estimativas dos impactos de cada fator com-todos-os-demais-mantidos-constantes.\n",
    "* Não nos diz nada a respeito da interação entre as variáveis. O modelo não captura isso.\n",
    "* Podem ser adicinadas variáveis que relacionam outras duas afim de promover essa relação.\n",
    "\n",
    "### O Benefício do Ajuste\n",
    "\n",
    "* Podemos olhar para $R^{2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_r_squared(x, y, beta):\n",
    "    sum_of_squared_errors = sum(error(x_i, y_i, beta)**2\n",
    "                               for x_i, y_i in zip(x,y))\n",
    "    return 1.0-sum_of_squared_errors/total_sum_of_squares(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adicionar novas variáveis a uma regressão irá necessáriamente aumentar $R^{2}$, pois, o modelo de regressão simples é apenas um caso especial do modelo de regressão múltipla.\n",
    "* Além disso, em regressão múltipla também precisamos ver os erros padrões dos coeficientes:\n",
    "  * Medem quão certas estão as nossas estimativas para cada $\\beta_{1}$.\n",
    "  \n",
    "  \n",
    "* A regressão como um todo pode ajustar os dados muito bem, entretanto, se algumas das variáveis forem correlacionadas, os coeficientes podem não significar tanto.\n",
    "\n",
    "### Digressão: A Inicialização\n",
    "\n",
    "* Imagine que temos um modelo de N pontos de dados gerados por alguma distribuição desconhecida.\n",
    "* Podemos calcular a mediana dos dos dados observados como estimativa da mediana da distribuição.\n",
    "* Essa estimativa pode não ser tão confiante, uma vez que, se os dados estiverem todos próximos de 100, a mediana é próxima de 100. Entretanto, se metade dos dados forem próximos de 0 e a outra metade próxima de 200, não é possível ter certeza sobre a estimativa. \n",
    "* Não podemos pegar novos modelos repetidamente, mas, podemos inicializar novos conjuntos de dados escolhendo n pontos de dados com substituição a partir dos nossos dados e então computar as medianas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(data):\n",
    "    # Amostra aleatoriamente len(dados) elementos com substituição\n",
    "    return [random.choice(data) for _ in data]\n",
    "\n",
    "def bootstrap_statistic(data, stats_fn, num_samples):\n",
    "    # Avalia stats_fn em num_samples amostras de inicialização a partir dos dados\n",
    "    return [stats_fn(bootstrap_sample(data))\n",
    "           for _ in range(num_samples)]\n",
    "\n",
    "# Considere os dois conjuntos de dados abaixo\n",
    "\n",
    "# 101 pontos todos muito próximos de 100\n",
    "close_to_100 = [99.5 + random.random() for _ in range(101)]\n",
    "\n",
    "# 101 pontos, 50 próximos de 0 e 50 próximos de 200\n",
    "far_from_100 = ([99.5 + random.random()] +\n",
    "               [random.random() for _ in range(50)] +\n",
    "               [200 + random.random() for _ in range(50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se computar a mediana para cada, ambas serão próximas de 100.\n",
    "* Se olhar para:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99.93100305092503,\n",
       " 100.00762160181353,\n",
       " 100.13577247235112,\n",
       " 100.0301057186029,\n",
       " 99.98171525813126,\n",
       " 100.0164316288823,\n",
       " 100.07701862232292,\n",
       " 99.98491949971222,\n",
       " 100.09246026940899,\n",
       " 100.0164316288823,\n",
       " 99.99802047195028,\n",
       " 100.06144958715034,\n",
       " 100.01732929373702,\n",
       " 100.03734521909514,\n",
       " 100.00762160181353,\n",
       " 100.0301057186029,\n",
       " 99.98011896010028,\n",
       " 99.99802047195028,\n",
       " 100.00762160181353,\n",
       " 100.01732929373702,\n",
       " 100.01812549857686,\n",
       " 100.0301057186029,\n",
       " 100.00762160181353,\n",
       " 99.98171525813126,\n",
       " 99.93100305092503,\n",
       " 99.98011896010028,\n",
       " 99.98491949971222,\n",
       " 100.06144958715034,\n",
       " 100.04615232524637,\n",
       " 99.90338746302469,\n",
       " 99.98491949971222,\n",
       " 100.0301057186029,\n",
       " 100.0301057186029,\n",
       " 100.09246026940899,\n",
       " 100.0301057186029,\n",
       " 99.98491949971222,\n",
       " 100.01812549857686,\n",
       " 99.98171525813126,\n",
       " 100.0164316288823,\n",
       " 100.0301057186029,\n",
       " 100.04615232524637,\n",
       " 100.03734521909514,\n",
       " 100.0164316288823,\n",
       " 100.03734521909514,\n",
       " 100.00379646746806,\n",
       " 100.04615232524637,\n",
       " 100.09246026940899,\n",
       " 100.01812549857686,\n",
       " 100.0301057186029,\n",
       " 100.00379646746806,\n",
       " 100.13577247235112,\n",
       " 100.07701862232292,\n",
       " 100.0301057186029,\n",
       " 100.01732929373702,\n",
       " 99.98171525813126,\n",
       " 99.98491949971222,\n",
       " 100.01732929373702,\n",
       " 100.06144958715034,\n",
       " 99.98491949971222,\n",
       " 100.00379646746806,\n",
       " 100.0301057186029,\n",
       " 100.01812549857686,\n",
       " 99.98491949971222,\n",
       " 99.98171525813126,\n",
       " 99.99802047195028,\n",
       " 100.01732929373702,\n",
       " 100.01812549857686,\n",
       " 100.09246026940899,\n",
       " 100.0164316288823,\n",
       " 99.94162304837862,\n",
       " 100.03734521909514,\n",
       " 99.93100305092503,\n",
       " 100.09066813680626,\n",
       " 100.04615232524637,\n",
       " 100.0164316288823,\n",
       " 100.01812549857686,\n",
       " 99.96252987144312,\n",
       " 100.06144958715034,\n",
       " 99.99802047195028,\n",
       " 100.03734521909514,\n",
       " 100.00379646746806,\n",
       " 100.06144958715034,\n",
       " 100.1100537486017,\n",
       " 100.01732929373702,\n",
       " 100.09246026940899,\n",
       " 100.04615232524637,\n",
       " 100.00379646746806,\n",
       " 100.01732929373702,\n",
       " 100.0164316288823,\n",
       " 100.01812549857686,\n",
       " 100.07701862232292,\n",
       " 99.94817857225551,\n",
       " 100.00379646746806,\n",
       " 100.00762160181353,\n",
       " 99.96252987144312,\n",
       " 100.06144958715034,\n",
       " 99.98491949971222,\n",
       " 100.00379646746806,\n",
       " 100.03734521909514,\n",
       " 100.0301057186029]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_statistic(close_to_100, median, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* você verá a maioria dos números próximos a 100.\n",
    "* Enquanto, se olhar para:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8650749483970116,\n",
       " 0.8875569371107614,\n",
       " 200.1257534634308,\n",
       " 0.9671812155004635,\n",
       " 200.05201406674271,\n",
       " 200.04340410406178,\n",
       " 0.8581120922432314,\n",
       " 0.9835420161397569,\n",
       " 0.8875569371107614,\n",
       " 0.9017717078875573,\n",
       " 0.9671812155004635,\n",
       " 0.9835420161397569,\n",
       " 0.9128951951914043,\n",
       " 200.04340410406178,\n",
       " 200.05201406674271,\n",
       " 0.9835420161397569,\n",
       " 200.0385105081688,\n",
       " 200.0385105081688,\n",
       " 200.0385105081688,\n",
       " 200.0385105081688,\n",
       " 200.13955749383348,\n",
       " 200.12273409055376,\n",
       " 200.0214959897691,\n",
       " 0.8558396076164164,\n",
       " 99.9874355052895,\n",
       " 0.9128951951914043,\n",
       " 0.9017717078875573,\n",
       " 200.12273409055376,\n",
       " 0.9222494897497828,\n",
       " 200.1257534634308,\n",
       " 200.0214959897691,\n",
       " 200.05201406674271,\n",
       " 0.9790277553968125,\n",
       " 200.13955749383348,\n",
       " 0.9222494897497828,\n",
       " 0.9835420161397569,\n",
       " 0.9128951951914043,\n",
       " 0.9790277553968125,\n",
       " 200.1631627535096,\n",
       " 0.9222494897497828,\n",
       " 0.8875569371107614,\n",
       " 0.7679183749766814,\n",
       " 0.9128951951914043,\n",
       " 200.0214959897691,\n",
       " 0.8650749483970116,\n",
       " 200.0214959897691,\n",
       " 200.05201406674271,\n",
       " 200.05201406674271,\n",
       " 0.9671812155004635,\n",
       " 200.07260478975692,\n",
       " 0.9835420161397569,\n",
       " 200.0214959897691,\n",
       " 0.9790277553968125,\n",
       " 0.8581120922432314,\n",
       " 200.04340410406178,\n",
       " 200.29531536527415,\n",
       " 200.0385105081688,\n",
       " 200.0385105081688,\n",
       " 0.9835420161397569,\n",
       " 0.9222494897497828,\n",
       " 0.8558396076164164,\n",
       " 0.9835420161397569,\n",
       " 0.9671812155004635,\n",
       " 200.0385105081688,\n",
       " 200.0214959897691,\n",
       " 200.0385105081688,\n",
       " 200.07260478975692,\n",
       " 0.8581120922432314,\n",
       " 200.0385105081688,\n",
       " 200.05201406674271,\n",
       " 0.9835420161397569,\n",
       " 99.9874355052895,\n",
       " 200.05201406674271,\n",
       " 0.9128951951914043,\n",
       " 200.0385105081688,\n",
       " 200.12273409055376,\n",
       " 0.9671812155004635,\n",
       " 99.9874355052895,\n",
       " 200.0214959897691,\n",
       " 0.8581120922432314,\n",
       " 200.04340410406178,\n",
       " 0.9222494897497828,\n",
       " 0.9128951951914043,\n",
       " 0.9017717078875573,\n",
       " 200.1631627535096,\n",
       " 0.8558396076164164,\n",
       " 0.9671812155004635,\n",
       " 0.7679183749766814,\n",
       " 0.9835420161397569,\n",
       " 0.9222494897497828,\n",
       " 200.0385105081688,\n",
       " 0.9835420161397569,\n",
       " 0.8650749483970116,\n",
       " 200.13955749383348,\n",
       " 200.07260478975692,\n",
       " 99.9874355052895,\n",
       " 0.8581120922432314,\n",
       " 200.0214959897691,\n",
       " 200.13955749383348,\n",
       " 200.07260478975692]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_statistic(far_from_100, median, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Muitos números estão próximos de 0 e muitos estão próximos de 200.\n",
    "* O desvio padrão do primeiro conjunto é próximo de 0 enquanto o do segundo é próximo de 100.\n",
    "\n",
    "### Erros Padrões de Coeficientes de Regressão\n",
    "\n",
    "* Podemos usar a mesma abordagem para calcular os erros padrões dos coeficientes de regressão.\n",
    "* Repetidamente tiramos uma amostra de inicialização dos dados e calculamos beta com base na amostra.\n",
    "* Se o coeficiente de uma das variáveis independentes não variar muito pelos modelos, podemos confiar que a estimativa está relativamente correta. Se variar muito, não podemos ficar tão confiantes assim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.953551702104508, 0.06288763616183773, 0.11722269488203318, 0.8591786495949066]\n"
     ]
    }
   ],
   "source": [
    "def estimate_sample_beta(sample):\n",
    "    # sample é uma lista de pares (x_i, y_i)\n",
    "    x_sample, y_sample = list(zip(*sample))\n",
    "    return estimate_beta(x_sample, y_sample)\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "bootstrap_betas = bootstrap_statistic(list(zip(x, daily_minutes_good)),\n",
    "                                     estimate_sample_beta,\n",
    "                                     100)\n",
    "\n",
    "# Podemos calcular o desvio padrão de cada coeficiente\n",
    "bootstrap_standard_errors = [\n",
    "    standard_deviation([beta[i] for beta in bootstrap_betas])\n",
    "    for i in range(4)]\n",
    "\n",
    "print(bootstrap_standard_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização\n",
    "\n",
    "* Quanto mais variáveis você usar, maior a probabilidade de você sobreajustar seu modelo ao conjunto de treinamento.\n",
    "* Quanto mais coeficientes não-zero você tiver, mais difícil será entendê-los.\n",
    "* Se o objetivo é explicar um fenômeno, um modelo com 3 fatores pode ser melhor do que um modelo com centenas. \n",
    "* A regularização é uma abordagem na qual adicionamos ao termo de erro uma penalidade que aumenta beta. \n",
    "  * Então minimizamos o erro e a penalidade combinadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
